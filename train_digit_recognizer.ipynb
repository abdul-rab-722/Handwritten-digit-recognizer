{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64c8521",
   "metadata": {},
   "source": [
    "The core features of the model are as follows −\n",
    "\n",
    "- Input layer consists of (1, 8, 28) values.\n",
    "\n",
    "- First layer, Conv2D consists of 32 filters and ‘relu’ activation function with kernel size, (3,3).\n",
    "\n",
    "- Second layer, Conv2D consists of 64 filters and ‘relu’ activation function with kernel size, (3,3).\n",
    "\n",
    "- Thrid layer, MaxPooling has pool size of (2, 2).\n",
    "\n",
    "- Fifth layer, Flatten is used to flatten all its input into single dimension.\n",
    "\n",
    "- Sixth layer, Dense consists of 128 neurons and ‘relu’ activation function.\n",
    "\n",
    "- Seventh layer, Dropout has 0.5 as its value.\n",
    "\n",
    "- Eighth and final layer consists of 10 neurons and ‘softmax’ activation function.\n",
    "\n",
    "- Use categorical_crossentropy as loss function.\n",
    "\n",
    "- Use Adadelta() as Optimizer.\n",
    "\n",
    "- Use accuracy as metrics.\n",
    "\n",
    "- Use 128 as batch size.\n",
    "\n",
    "- Use 10 as epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f95ae",
   "metadata": {},
   "source": [
    "### Step 1 − Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2919750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras import backend as K \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31d860",
   "metadata": {},
   "source": [
    "### Step 2 − Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bcd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754cb32",
   "metadata": {},
   "source": [
    "### Step 3 − Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ffd40",
   "metadata": {},
   "source": [
    "Let us change the dataset according to our model, so that it can be feed into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2879e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28 \n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else: \n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32') \n",
    "x_train /= 255 \n",
    "x_test /= 255 \n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 10) \n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, 10)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f9aab",
   "metadata": {},
   "source": [
    "### Step 4 − Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71d6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(32, kernel_size = (3, 3),  \n",
    "   activation = 'relu', input_shape = input_shape)) \n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation = 'relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b78946",
   "metadata": {},
   "source": [
    "### Step 5 − Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tensorflow.keras.losses.categorical_crossentropy, \n",
    "   optimizer = tensorflow.keras.optimizers.Adadelta(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae30ce3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 264s 560ms/step - loss: 2.2833 - accuracy: 0.1695 - val_loss: 2.2522 - val_accuracy: 0.3769\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 267s 570ms/step - loss: 2.2326 - accuracy: 0.2878 - val_loss: 2.1892 - val_accuracy: 0.5596\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 261s 557ms/step - loss: 2.1646 - accuracy: 0.3920 - val_loss: 2.1002 - val_accuracy: 0.6400\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 263s 561ms/step - loss: 2.0697 - accuracy: 0.4632 - val_loss: 1.9762 - val_accuracy: 0.6868\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 264s 562ms/step - loss: 1.9410 - accuracy: 0.5165 - val_loss: 1.8129 - val_accuracy: 0.7198\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 269s 574ms/step - loss: 1.7794 - accuracy: 0.5605 - val_loss: 1.6120 - val_accuracy: 0.7459\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 267s 569ms/step - loss: 1.5977 - accuracy: 0.5965 - val_loss: 1.3944 - val_accuracy: 0.7738\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 271s 577ms/step - loss: 1.4206 - accuracy: 0.6253 - val_loss: 1.1912 - val_accuracy: 0.7947\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 265s 564ms/step - loss: 1.2666 - accuracy: 0.6508 - val_loss: 1.0237 - val_accuracy: 0.8097\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 262s 559ms/step - loss: 1.1437 - accuracy: 0.6768 - val_loss: 0.8945 - val_accuracy: 0.8234\n",
      "The model has successfully trained\n",
      "Saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "   x_train, y_train, \n",
    "   batch_size = 128, \n",
    "   epochs = 10, \n",
    "   verbose = 1, \n",
    "   validation_data = (x_test, y_test)\n",
    ")\n",
    "\n",
    "print(\"The model has successfully trained\")\n",
    "\n",
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123d92f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.2832517623901367,\n",
       "  2.2326109409332275,\n",
       "  2.164642095565796,\n",
       "  2.0697269439697266,\n",
       "  1.941028118133545,\n",
       "  1.7794055938720703,\n",
       "  1.5976860523223877,\n",
       "  1.4206007719039917,\n",
       "  1.266602873802185,\n",
       "  1.1436580419540405],\n",
       " 'accuracy': [0.16948333382606506,\n",
       "  0.2877666652202606,\n",
       "  0.3919833302497864,\n",
       "  0.46318334341049194,\n",
       "  0.5165333151817322,\n",
       "  0.560533344745636,\n",
       "  0.5965166687965393,\n",
       "  0.625333309173584,\n",
       "  0.6508333086967468,\n",
       "  0.6768166422843933],\n",
       " 'val_loss': [2.252230167388916,\n",
       "  2.18920636177063,\n",
       "  2.100191116333008,\n",
       "  1.9761779308319092,\n",
       "  1.812874436378479,\n",
       "  1.6119798421859741,\n",
       "  1.3944308757781982,\n",
       "  1.1911503076553345,\n",
       "  1.0236570835113525,\n",
       "  0.8945151567459106],\n",
       " 'val_accuracy': [0.37689998745918274,\n",
       "  0.5595999956130981,\n",
       "  0.6399999856948853,\n",
       "  0.6868000030517578,\n",
       "  0.7197999954223633,\n",
       "  0.7458999752998352,\n",
       "  0.7738000154495239,\n",
       "  0.794700026512146,\n",
       "  0.8097000122070312,\n",
       "  0.8234000205993652]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edb5a3",
   "metadata": {},
   "source": [
    "### Step 7 − Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2b581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8945152163505554\n",
      "Test accuracy: 0.8234000205993652\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265711c",
   "metadata": {},
   "source": [
    "### Step 8 − Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390919b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4]\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test) \n",
    "pred = np.argmax(pred, axis = 1)[:5] \n",
    "label = np.argmax(y_test,axis = 1)[:5] \n",
    "\n",
    "print(pred) \n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd809c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
